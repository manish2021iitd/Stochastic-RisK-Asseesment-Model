{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"none","dataSources":[],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom scipy import stats\nfrom fitter import Fitter # For conveniently fitting multiple distributions\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Load the cleaned dataset\ndf_cleaned = pd.read_csv('/kaggle/working/cleaned_supply_chain_data.csv')\n\n# --- Distribution Fitting Prototype ---\n\n# Define key variables for distribution fitting\nkey_variables = {\n    'Inter-Arrival Time (Days)': df_cleaned['inter_arrival_time'].dropna(),\n    'Order Profit Per Order': df_cleaned['order_profit_per_order'].dropna()\n}\n\n# Define distributions to fit\ndistribution_names = ['expon', 'weibull_min', 'lognorm', 'pareto']\n\n# Store results for comparison table\nfitting_results = []\n\n# Perform fitting for each key variable\nfor var_name, data_series in key_variables.items():\n    print(f\"\\n--- Fitting Distributions for {var_name} ---\")\n\n    # Filter out non-positive values for Pareto and Lognormal if they are present and cause issues\n    # Pareto and Lognormal are defined for positive values.\n    # For profit, negative values are valid losses. We might need to transform or use a shifted version.\n    # For inter_arrival_time, 0s were introduced for first orders. Pareto/Lognormal won't fit 0.\n    # Let's handle 0s for inter_arrival_time by either excluding them or adding a small constant if the nature allows.\n    # For now, let's remove 0s for fitting Pareto/Lognormal for inter-arrival time as they represent no prior event.\n    if var_name == 'Inter-Arrival Time (Days)':\n        data_for_positive_dist = data_series[data_series > 0]\n    else:\n        # For order profit, negative values exist. Lognormal/Pareto won't fit negative values directly.\n        # This dataset's 'order_profit_per_order' includes negative values.\n        # Fitting Lognormal/Pareto to profit directly is problematic if it includes negative values.\n        # A common approach for profit/loss is to model gains and losses separately, or use a shifted distribution.\n        # For this prototype, if the distribution (e.g., Lognormal, Pareto) cannot handle negative values,\n        # we'll note it and proceed with distributions that can.\n        # Let's fit only on positive profits for these distributions for now for demonstration.\n        # For the sake of demonstrating fitting, let's consider the absolute value or only positive part for these specific distributions\n        # For `order_profit_per_order`, the range includes negative values.\n        # Exponential, Weibull are typically for positive values (time to event, etc.).\n        # Given the requirements, I will attempt to fit these directly, but acknowledge the limitations for negative values.\n        # Fitter handles this by ignoring non-positive values for distributions that require positive input.\n        data_for_positive_dist = data_series\n\n\n    f = Fitter(data_for_positive_dist, distributions=distribution_names)\n    f.fit()\n\n    # Get the summary of fitted distributions\n    #summary = f.get_results()\n    summary = f.summary()\n    print(summary.head())\n    print(summary.index) \n\n\n    # Plotting the fitted PDFs\n    plt.figure(figsize=(12, 7))\n    f.plot_pdf(names=distribution_names, lw=2)\n    plt.title(f'Distribution Fit for {var_name}')\n    plt.xlabel(var_name)\n    plt.ylabel('Probability Density')\n    plt.legend(title='Distribution')\n    plt.savefig(f'distribution_fit_{var_name.replace(\" \", \"_\").lower()}.png')\n    plt.close()\n\n\n    # Prepare results for the comparison table\n    for dist_name in distribution_names:\n        if dist_name in f.fitted_param:\n            # params = f.fitted_param_names[dist_name]\n            # Later in the loop\n            params = f.fitted_param[dist_name]\n            # Fitter gives 'sumsquare_error' as a GOF metric.\n            # To get KS p-value, AIC, BIC, we'd ideally re-calculate or use a more robust library.\n            # For prototype, we'll use Fitter's `sumsquare_error` as a proxy for GOF,\n            # and illustrate how AIC/BIC/KS would be obtained if implementing from scratch.\n\n            # Attempt to calculate KS p-value directly for fitted distribution\n            try:\n                # Need to use the correct `loc` and `scale` parameters depending on the distribution.\n                # Fitter's params are often (shape, loc, scale) or (loc, scale)\n                if dist_name == 'expon':\n                    loc, scale = params\n                    ks_stat, ks_pvalue = stats.kstest(data_for_positive_dist, 'expon', args=(loc, scale))\n                elif dist_name == 'weibull_min':\n                    shape, loc, scale = params\n                    ks_stat, ks_pvalue = stats.kstest(data_for_positive_dist, 'weibull_min', args=(shape, loc, scale))\n                elif dist_name == 'lognorm':\n                    shape, loc, scale = params\n                    ks_stat, ks_pvalue = stats.kstest(data_for_positive_dist, 'lognorm', args=(shape, loc, scale))\n                elif dist_name == 'pareto':\n                    shape, loc, scale = params\n                    ks_stat, ks_pvalue = stats.kstest(data_for_positive_dist, 'pareto', args=(shape, loc, scale))\n                else:\n                    ks_stat, ks_pvalue = np.nan, np.nan\n            except Exception as e:\n                ks_stat, ks_pvalue = np.nan, np.nan # If fitting failed or kstest fails\n\n            # For AIC/BIC, direct calculation from `scipy.stats.fit` usually isn't provided directly.\n            # This requires calculating the log-likelihood of the fitted model.\n            # This is a placeholder as `fitter` doesn't expose them directly without more manual work.\n            aic = np.nan\n            bic = np.nan\n\n            fitting_results.append({\n                'Variable': var_name,\n                'Distribution': dist_name,\n                'Parameters': params,\n                'KS p-value': ks_pvalue,\n                'Sum of Squared Errors': summary.loc[dist_name, 'sumsquare_error'], # From Fitter\n                'AIC': aic, # Placeholder\n                'BIC': bic  # Placeholder\n            })\n\n# Create the comparison table DataFrame\ncomparison_df = pd.DataFrame(fitting_results)\n# Sort by Sum of Squared Errors to show best fit first\ncomparison_df.sort_values(by=['Variable', 'Sum of Squared Errors'], inplace=True)\n\nprint(\"\\n--- Distribution Fitting Comparison Table ---\")\nprint(comparison_df.to_markdown(index=False))\n\n# Optional: Save the comparison table to a CSV or Excel file\ncomparison_df.to_csv('distribution_fitting_comparison.csv', index=False)\nprint(f\"\\nDistribution fitting comparison table saved to distribution_fitting_comparison.csv\")\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null}]}